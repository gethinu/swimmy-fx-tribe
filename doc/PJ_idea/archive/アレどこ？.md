# アレどこ？

# Role Definition

あなたは、コンピュータビジョンとセマンティックWebを融合させる、空間知能のアーキテクトである。
私の「Project Swimmy」において、物理空間の検索エンジン**「Project FINDER」**のMVPを設計・実装せよ。

# Core Philosophy

「人間は物を失くす生き物だが、機械は全てを記録できる」。
高価な専用ハードは不要。Rustの軽量さを活かし、古いスマホやWebカメラのエッジデバイス上で`YOLO`を走らせ、プライバシーを守りながら（映像をクラウドに送らず）メタデータだけを蓄積する。
ユーザーの「ハサミどこ？」という曖昧な問いに対し、Lispが文脈を解釈して「右の引き出しです」と即答する。

# Architecture & Tech Stack (The Lisp-Rust Axis)

1. **The Sentinel Eye (Rust)**:
    - **役割**: カメラ映像を常時監視し、物体の移動イベントだけを記録する。
    - **技術**: `tch-rs` (YOLOv8 binding) or `opencv`, `sled` (Embedded DB).
    - **Logic**:
        - `Movement Trigger`: 画面に変化がない時はスリープし、動体検知時のみ推論を走らせる（省エネ）。
        - `Object Tracking`: 「ハサミ」が `(x1, y1)` から `(x2, y2)` へ移動し、消失（＝引き出しに入った or 持ち去られた）した瞬間をログに残す。
2. **The Semantic Mapper (Common Lisp)**:
    - **役割**: 座標データ `(x, y)` を、人間が理解できる「意味ある場所（テレビ台の上）」に変換し、検索クエリを処理する。
    - **Logic**:
        - `(map-coordinate-to-label x y)`: 事前に定義されたゾーン（例: Desk, Sofa, Shelf）と物体の座標を照合。
        - `(solve-query "nail clipper")`: DBを逆検索し、最新のタイムスタンプを持つ場所を返す。

# Immediate Objective

このアーキテクチャに基づき、以下の2つのコードブロックを提示せよ。

## 1. Rust: The Event Recorder (Body)

- Webカメラからフレームを取得し、YOLOモデルで物体検出を行い、物体の座標が大きく変化した（移動した）場合のみ、その「物体名」「時刻」「座標」「スナップショット画像」をローカルDBに保存するループ処理の実装。

## 2. Lisp: The Location Resolver (Brain)

- `(find-object object-name history-log)` 関数。
- 物体の移動ログを受け取り、「現在どこにあるか（Last Known Location）」を特定するロジック。
- 単なる座標ではなく、「机の上からバッグの中へ移動しました」という**自然言語の回答**を生成するフォーマッター。

さあ、ADHDの脳を外部拡張し、世界から「探し物」という時間を消滅させよう。